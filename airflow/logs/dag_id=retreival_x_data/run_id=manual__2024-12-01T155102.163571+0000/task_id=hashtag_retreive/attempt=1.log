[2024-12-01T15:51:04.581+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2024-12-01T15:51:04.597+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: retreival_x_data.hashtag_retreive manual__2024-12-01T15:51:02.163571+00:00 [queued]>
[2024-12-01T15:51:04.604+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: retreival_x_data.hashtag_retreive manual__2024-12-01T15:51:02.163571+00:00 [queued]>
[2024-12-01T15:51:04.605+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2024-12-01T15:51:04.626+0000] {taskinstance.py:2889} INFO - Executing <Task(PythonOperator): hashtag_retreive> on 2024-12-01 15:51:02.163571+00:00
[2024-12-01T15:51:04.637+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=942) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-12-01T15:51:04.638+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'retreival_x_data', 'hashtag_retreive', 'manual__2024-12-01T15:51:02.163571+00:00', '--job-id', '80', '--raw', '--subdir', 'DAGS_FOLDER/retreive_data.py', '--cfg-path', '/tmp/tmps4aug_q0']
[2024-12-01T15:51:04.639+0000] {standard_task_runner.py:72} INFO - Started process 945 to run task
[2024-12-01T15:51:04.639+0000] {standard_task_runner.py:105} INFO - Job 80: Subtask hashtag_retreive
[2024-12-01T15:51:04.680+0000] {task_command.py:467} INFO - Running <TaskInstance: retreival_x_data.hashtag_retreive manual__2024-12-01T15:51:02.163571+00:00 [running]> on host 3903981c8fb7
[2024-12-01T15:51:04.751+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='nou' AIRFLOW_CTX_DAG_ID='retreival_x_data' AIRFLOW_CTX_TASK_ID='hashtag_retreive' AIRFLOW_CTX_EXECUTION_DATE='2024-12-01T15:51:02.163571+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-01T15:51:02.163571+00:00'
[2024-12-01T15:51:04.753+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-01T15:51:04.753+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-01T15:51:04.753+0000] {logging_mixin.py:190} INFO - Current task name:hashtag_retreive state:running start_date:2024-12-01 15:51:04.597637+00:00
[2024-12-01T15:51:04.753+0000] {logging_mixin.py:190} INFO - Dag name:retreival_x_data and current dag run status:running
[2024-12-01T15:51:04.754+0000] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-01T15:51:04.754+0000] {logging_mixin.py:190} INFO - finsihed task
[2024-12-01T15:51:06.417+0000] {logging_mixin.py:190} INFO - Loading .env file
Loaded .env file

usage: python scraper [option] ... [arg] ...

Twitter Scraper is a tool that allows you to scrape tweets from twitter
without using Twitter's API.

options:
  -h, --help            show this help message and exit
  --mail MAIL           Your Twitter mail.
  --user USER           Your Twitter username.
  --password PASSWORD   Your Twitter password.
  -t TWEETS, --tweets TWEETS
                        Number of tweets to scrape (default: 50)
  -u USERNAME, --username USERNAME
                        Twitter username. Scrape tweets from a user's profile.
  -ht HASHTAG, --hashtag HASHTAG
                        Twitter hashtag. Scrape tweets from a hashtag.
  -ntl [NO_TWEETS_LIMIT], --no_tweets_limit [NO_TWEETS_LIMIT]
                        Set no limit to the number of tweets to scrape (will
                        scrap until no more tweets are available).
  -q QUERY, --query QUERY
                        Twitter query or search. Scrape tweets from a query or
                        search.
  -a ADD, --add ADD     Additional data to scrape and save in the .csv file.
  --latest              Scrape latest tweets
  --top                 Scrape top tweets
[2024-12-01T15:51:06.418+0000] {logging_mixin.py:190} INFO - finsihed task
[2024-12-01T15:51:06.418+0000] {python.py:240} INFO - Done. Returned value was: None
[2024-12-01T15:51:06.880+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-01T15:51:06.881+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=retreival_x_data, task_id=hashtag_retreive, run_id=manual__2024-12-01T15:51:02.163571+00:00, execution_date=20241201T155102, start_date=20241201T155104, end_date=20241201T155106
[2024-12-01T15:51:06.892+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-01T15:51:06.892+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-01T15:51:06.893+0000] {logging_mixin.py:190} INFO - Dag name:retreival_x_data queued_at:2024-12-01 15:51:02.185297+00:00
[2024-12-01T15:51:06.893+0000] {logging_mixin.py:190} INFO - Task hostname:3903981c8fb7 operator:PythonOperator
[2024-12-01T15:51:06.941+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2024-12-01T15:51:06.955+0000] {taskinstance.py:3895} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-12-01T15:51:06.956+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
